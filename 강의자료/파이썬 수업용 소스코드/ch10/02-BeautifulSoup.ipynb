{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7054b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4->bs4)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: typing-extensions, soupsieve, beautifulsoup4, bs4\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [bs4]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.14.2 bs4-0.0.2 soupsieve-2.8 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f009d06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs('<h1>Hello</h1>')\n",
    "soup.find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a26697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page title\n",
      "This is a heading\n",
      "a/b/c/d/e/f/g/h/i/This is a paragraph./This is another paragraph./"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오기 - find / find_all\n",
    "import requests\n",
    "address = 'http://ggoreb.com/python/html/example.html'\n",
    "res = requests.get(address)\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(res.text)\n",
    "\n",
    "print(soup.find('title').text) # HTML 제목\n",
    "print(soup.find('h1').text) # h1\n",
    "p_list = soup.find_all('p') # p (2개 이상)\n",
    "for p in p_list:\n",
    "  print(p.text, end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f81875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['ex_class']\n",
      "['ex_id']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 추출 (속성)\n",
    "print(soup.find('title').attrs.get('class'))\n",
    "print(soup.find_all('div')[1]['class'])\n",
    "print(soup.find_all('div')[2].get_attribute_list('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d467f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "d\n",
      "e\n",
      "f\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 추출 - 속성을 지정하여 요소 선택\n",
    "print(soup.find('div', {'class': 'ex_class'}).text)\n",
    "print(soup.find(attrs={'class': 'ex_class'}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37fcae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a heading']\n",
      "['This is a heading', 'This is a paragraph.']\n"
     ]
    }
   ],
   "source": [
    "# 텍스트가 일치하는 요소 선택\n",
    "print(soup.find_all(string='This is a heading'))\n",
    "\n",
    "# 텍스트가 일치하는 요소 선택 (정규식)\n",
    "import re\n",
    "print(soup.find_all(string=re.compile(r'.+is\\s{1}a\\s{1}.+')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9e77b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML HOME\n",
      "HTML Introduction\n",
      "HTML Editors\n",
      "HTML Basic\n",
      "HTML Elements\n",
      "HTML Attributes\n",
      "HTML Headings\n",
      "HTML Paragraphs\n",
      "HTML Styles\n",
      "HTML Formatting\n",
      "HTML Quotations\n",
      "HTML Comments\n",
      "HTML Colors\n",
      "HTML CSS\n",
      "HTML Links\n",
      "HTML Images\n",
      "HTML Favicon\n",
      "HTML Page Title\n",
      "HTML Tables\n",
      "HTML Lists\n",
      "HTML Block & Inline\n",
      "HTML Div\n",
      "HTML Classes\n",
      "HTML Id\n",
      "HTML Iframes\n",
      "HTML JavaScript\n",
      "HTML File Paths\n",
      "HTML Head\n",
      "HTML Layout\n",
      "HTML Responsive\n",
      "HTML Computercode\n",
      "HTML Semantics\n",
      "HTML Style Guide\n",
      "HTML Entities\n",
      "HTML Symbols\n",
      "HTML Emojis\n",
      "HTML Charsets\n",
      "HTML URL Encode\n",
      "HTML vs. XHTML\n",
      "HTML Forms\n",
      "HTML Form Attributes\n",
      "HTML Form Elements\n",
      "HTML Input Types\n",
      "HTML Input Attributes\n",
      "Input Form Attributes\n",
      "HTML Canvas\n",
      "HTML SVG\n",
      "HTML Media\n",
      "HTML Video\n",
      "HTML Audio\n",
      "HTML Plug-ins\n",
      "HTML YouTube\n",
      "HTML Web APIs\n",
      "HTML Geolocation\n",
      "HTML Drag and Drop\n",
      "HTML Web Storage\n",
      "HTML Web Workers\n",
      "HTML SSE\n",
      "HTML Examples\n",
      "HTML Editor\n",
      "HTML Quiz\n",
      "HTML Exercises\n",
      "HTML Website\n",
      "HTML Syllabus\n",
      "HTML Study Plan\n",
      "HTML Interview Prep\n",
      "HTML Bootcamp\n",
      "HTML Certificate\n",
      "HTML Summary\n",
      "HTML Accessibility\n",
      "HTML Tag List\n",
      "HTML Attributes\n",
      "HTML Global Attributes\n",
      "HTML Browser Support\n",
      "HTML Events\n",
      "HTML Colors\n",
      "HTML Canvas\n",
      "HTML Audio/Video\n",
      "HTML Doctypes\n",
      "HTML Character Sets\n",
      "HTML URL Encode\n",
      "HTML Lang Codes\n",
      "HTTP Messages\n",
      "HTTP Methods\n",
      "PX to EM Converter\n",
      "Keyboard Shortcuts\n"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오기 - select_one / select\n",
    "import requests\n",
    "address = 'https://www.w3schools.com/html/default.asp'\n",
    "res = requests.get(address)\n",
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(res.text)\n",
    "a_list = soup.select('#leftmenuinner h2 ~ a')\n",
    "for a in a_list:\n",
    "  print(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd83e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kim 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/36h_lw591jj3yhntkbh1_t040000gn/T/ipykernel_12111/3638413532.py:6: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = bs(res.text)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오기 - XML\n",
    "import requests\n",
    "address = 'http://ggoreb.com/python/xml/data1.xml'\n",
    "res = requests.get(address)\n",
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(res.text)\n",
    "person = soup.find('person')\n",
    "name = person.find('name')\n",
    "number = person.find('number')\n",
    "print(name.text, number.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ce77bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kim 1\n",
      "lee 2\n",
      "park 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/36h_lw591jj3yhntkbh1_t040000gn/T/ipykernel_12111/3854456678.py:6: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = bs(res.text)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오기 - XML\n",
    "import requests\n",
    "address = 'http://ggoreb.com/python/xml/data2.xml'\n",
    "res = requests.get(address)\n",
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(res.text)\n",
    "persons = soup.find_all('person')\n",
    "for person in persons:\n",
    "  print(person.find('name').text, person.find('number').text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
